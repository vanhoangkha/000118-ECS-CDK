[
{
	"uri": "/6-createservice/6.1-createnewstack/",
	"title": " Create a New Stack for Product Service",
	"tags": [],
	"description": "",
	"content": "Create a New Stack for Product Service Open your CDK project and create a new stack named ProductsServiceStack. Have ProductsServiceStack inherit from the Stack class from the amazon.awscdk library.\nTo create the ProductsServiceStack, we need to include several dependencies such as VPC, Cluster, NetworkLoadBalancer, ApplicationLoadBalancer, and Repository that were created earlier. Therefore, we need to define a record class named ProductsServiceProps to pass into the ProductsServiceStack. Add the following code snippet outside the ClusterStack class:\nrecord ProductsServiceProps( Vpc vpc, Cluster cluster, NetworkLoadBalancer networkLoadBalancer, ApplicationLoadBalancer applicationLoadBalancer, Repository repository ){} Create a Constructor: public ProductsServiceStack(final Construct scope, final String id, final StackProps props, ProductsServiceProps productsServiceProps) { super(scope, id, props); } "
},
{
	"uri": "/7-createapigateway/7.1-createnew/",
	"title": " Create API Gateway Resource",
	"tags": [],
	"description": "",
	"content": "Create API Gateway Resource Open your CDK project and create a new stack named ApiStack. Inherit the Stack class from the amazon.awscdk library: public class ApiStack extends Stack { } To create ApiStack, we require the VPC, Cluster, and NetworkLoadBalancer that we previously set up. Therefore, we need to create a record class named ApiStackProps to pass into ApiStack. Add the following code outside the ApiStack class: record ApiStackProps( NetworkLoadBalancer networkLoadBalancer, VpcLink vpcLink ){} Create the ApiStack constructor: public ApiStack(final Construct scope, final String id, final StackProps props, ApiStackProps apiStackProps) { super(scope, id, props); } Initialize a RestApi object named ECommerceAPI. This represents an API Gateway where API endpoints are declared and configured. RestApi restApi = new RestApi(this, \u0026#34;RestApi\u0026#34;, RestApiProps.builder() .restApiName(\u0026#34;ECommerceAPI\u0026#34;) .build() ); "
},
{
	"uri": "/8-createdynamodb/8.1-createdynamo/",
	"title": " Create DynamoDB with CDK",
	"tags": [],
	"description": "",
	"content": "Create DynamoDB with CDK First, open the file ProductsServiceStack.java. In the constructor, initialize a Table object with ID ProductsDdb. Table productsDdb = new Table(this, \u0026#34;ProductsDdb\u0026#34;, TableProps.builder() .build()); Define the partition key for the table. In this workshop, we will use the attribute id as the partition key with a data type of STRING. .partitionKey(Attribute.builder() .name(\u0026#34;id\u0026#34;) .type(AttributeType.STRING) .build()) Set the name for the DynamoDB table to products. .tableName(\u0026#34;products\u0026#34;) Next, configure the table to be deleted when your CDK stack resources are deleted. .removalPolicy(RemovalPolicy.DESTROY) Next, we need to specify the billing mode for the table. Here, the PROVISIONED mode is used, meaning you need to specify the read and write capacity units (RCUs and WCUs) for the table. .billingMode(BillingMode.PROVISIONED) Finally, we set the capacity units for the table. In this case, we set the read capacity and write capacity to 1, meaning the table will have minimal resources for read and write operations. .readCapacity(1) .writeCapacity(1) Grant Permissions for ProductService to Access DynamoDB Next, we grant permissions to the role of the task definition in Fargate to read and write data into the DynamoDB table productsDdb. This ensures that tasks in Fargate can interact with this DynamoDB table safely and according to the IAM (Identity and Access Management) policies in AWS. productsDdb.grantReadWriteData(fargateTaskDefinition.getTaskRole()); Add two environment variables (AWS_PRODUCTSDDB_NAME and AWS_REGION) to the task definition. envVariables.put(\u0026#34;AWS_PRODUCTSDDB_NAME\u0026#34;, productsDdb.getTableName()); envVariables.put(\u0026#34;AWS_REGION\u0026#34;, this.getRegion()); "
},
{
	"uri": "/5-createecs/5.1-createecscluster/",
	"title": " Create ECS Cluster",
	"tags": [],
	"description": "",
	"content": "Create ECS Cluster stack Open your CDK project and create a new stack named ClusterStack.java.\nTo create the ECS stack, we need the VPC that we previously created. Therefore, we need to create a record class to pass the VPC into the ECS Stack. Add the following code outside the ClusterStack class:\nrecord ClusterStackProps(Vpc vpc) {} Create the cluster property and a getter method within the ClusterStack class:\nprivate final Cluster cluster; public Cluster getCluster() { return cluster; } Create constructor public ClusterStack(final Construct scope, final String id, final StackProps props, ClusterStackProps clusterStackProps) { super(scope, id, props); } Initialize the Cluster object in the constructor of ClusterStack.java using the following code: this.cluster = new Cluster(this, \u0026#34;Cluster\u0026#34;, ClusterProps.builder() .build()); Set the name of the cluster to ECommerce* .clusterName(\u0026#34;ECommerce\u0026#34;) Add VPC to the cluster .vpc(clusterStackProps.vpc()) Finally, set containerInsight to true. .containerInsights(true) Organize ECS stack in CDK project Open the file named Fcj2024CdkApp in the root directory.\nCreate an ECS Stack with the ID Vpc using the following code snippet:\nClusterStack clusterStack = new ClusterStack(app, \u0026#34;Cluster\u0026#34;, StackProps.builder() .build()); Pass the previously created VPC to the ClusterStackProps of the ECS stack: new ClusterStackProps(vpcStack.getVpc()) Add environment and tags to the ECS Stack: .env(environment) .tags(infraTags) Because ECS requires a VPC but we cannot be certain whether the VPC has been created before the ECS, let\u0026rsquo;s add a dependency constraint to ensure that the ECS is only created after the VPC has been successfully created: clusterStack.addDependency(vpcStack); Deploy ECS Cluster using AWS CDK To deploy the ECS cluster, open your terminal and enter the following commands: Deploy all stacks using: cdk deploy --all Alternatively, you can skip the confirmation prompt by using: cdk deploy --all --require-approval never Deploy ECS Cluster using AWS CDK Check the newly created cluster:\nAccess the AWS console, navigate to ECS, and select Elastic Container Service. In the ECS interface, you should see a cluster named ECommerce that has been created.\n"
},
{
	"uri": "/3-createecr/3.1-createfirststack/",
	"title": " Create First CloudFormation Stack",
	"tags": [],
	"description": "",
	"content": "Prepare for CDK Project Delete the Fcj2024CdkStack file that was previously created. Remove unnecessary comments from the file. Create a new stack by creating a new Java file named EcrStack.java. Using CDK, you can write code to create stacks and CloudFormation resources. Your code will be compiled into corresponding CloudFormation templates, which can then be deployed by CloudFormation as usual.\nOnce the file is created, have the EcrStack class inherit from the Stack class provided by the AWS CDK library. Create the stack constructor. Create an AWS resource through a repository: First, declare the productsServiceRepository property with the following line:\nprivate final Repository productsServiceRepository; Then initialize the productsServiceRepository property in the constructor:\nthis.productsServiceRepository = new Repository(this, \u0026#34;ProductsService\u0026#34;, RepositoryProps.builder().build()); To initialize the Repository, add the following parameters: this: Refers to the current class object (usually a CDK stack). \u0026ldquo;ProductsService\u0026rdquo;: This is the unique name (ID) of the resource being created. This name must be unique within the scope of a CDK stack. Then create the ECR Repository properties using RepositoryProps.builder().build(): builder() is a static method of the RepositoryProps class to initialize a Builder object. This is a preparation step to set properties for RepositoryProps. The build() method on the Builder object is called to finalize the construction process and return a complete RepositoryProps object with the set properties. Specify the ECR repository name by adding .repositoryName(\u0026quot;productsservice\u0026quot;) before build(). Add .removalPolicy(RemovalPolicy.DESTROY) to ensure that when the CloudFormation stack is deleted, our resources will also be deleted. Allow overriding of images in the ECR repository by enabling IMMUTABLE with imageTagMutability(TagMutability.IMMUTABLE). Enable automatic image deletion when the ECR is deleted by adding autoDeleteImages(true). Create a getter method: public Repository getProductsServiceRepository() { return productsServiceRepository; } "
},
{
	"uri": "/4-createvpc/4.1-createvpc/",
	"title": " Create VPC and Nat Gateway",
	"tags": [],
	"description": "",
	"content": "Create VPC and NAT Gateway Open your CDK project and create a new stack named VpcStack.java.\nInherit from Stack from the awscdk library and create a constructor.\nDefine the VPC property and create a getter method.\nAdd the property in the VpcStack.java class: private final Vpc vpc; Then, create a getter method to access this VPC for other resources: public Vpc getVpc() { return vpc; } Initialize the VPC object in the constructor of VpcStack.java with the following code:\nthis.vpc = new Vpc(this, \u0026#34;Vpc\u0026#34;, VpcProps.builder().build()); Next, name the VPC as ECommerceVPC and specify the number of Availability Zones as 2 using the following code:\n.vpcName(\u0026#34;ECommerceVPC\u0026#34;) .maxAzs(2) If you want your VPC to be public and not use a NAT Gateway, you can add the following code:\n.natGateways(0) You may choose not to use a NAT Gateway in a lab environment to save costs, but avoid doing this in a production environment.\n"
},
{
	"uri": "/2-prerequiste/2.1-createinfrastructureproject/",
	"title": " Creating an Infrastructure Project with AWS CDK",
	"tags": [],
	"description": "",
	"content": "Setting up an Infrastructure Project using AWS CDK Open a terminal in the directory where you want to create the project.\nEnter the following command to initialize a new AWS CDK application using Java:\ncdk init app --language java This workshop will use Java. Alternatively, you can create the project with Python or TypeScript.\nOpen IntelliJ IDEA and import the project you just created. "
},
{
	"uri": "/9-intrumentingecs/9.1-reparetousexray/",
	"title": " Preparing Productsservice Spring Boot for AWS X-Ray Usage",
	"tags": [],
	"description": "",
	"content": "Preparing Productsservice Spring Boot for AWS X-Ray Usage In the productsservice project, open the build.gradle file and add the X-Ray SDK dependencies as follows:\nimplementation \u0026#39;com.amazonaws:aws-xray-recorder-sdk-spring:2.14.0\u0026#39; implementation \u0026#39;com.amazonaws:aws-xray-recorder-sdk-aws-sdk-v2:2.14.0\u0026#39; Preparing Productsservice Spring Boot for AWS X-Ray Usage Inside the config directory, create a new file named XRayConfig.java. Add the @Configuration annotation to the XRayConfig class. This annotation in Spring indicates that this class is used to define beans for the Spring application context. Next, create a logger object to record information related to AWS X-Ray operations in the application. @Configuration public class XRayConfig { private static final Logger LOG = LoggerFactory.getLogger(XRayConfig.class); } Create a constructor XRayConfig() within the XRayConfig class. In this constructor, configure AWS X-Ray as follows:\nruleFile: Read the configuration file xray-sampling-rules.json from the resources. This file contains sampling rules for AWS X-Ray, defining how AWS X-Ray should collect data. AWSXRayRecorder: Create an instance of AWSXRayRecorder with default configuration, including default plugins and sampling strategy from the specified file. AWSXRay.setGlobalRecorder(awsxRayRecorder): Set the newly created AWSXRayRecorder as the global recorder for AWS X-Ray. Trapping exceptions: In case the configuration file is not found, catch a FileNotFoundException and log an error message using the logger. public XRayConfig() { try { URL ruleFile = ResourceUtils .getURL(\u0026#34;classpath:xray/xray-sampling-rules.json\u0026#34;); AWSXRayRecorder awsxRayRecorder = AWSXRayRecorderBuilder.standard() .withDefaultPlugins() .withSamplingStrategy(new CentralizedSamplingStrategy(ruleFile)) .build(); AWSXRay.setGlobalRecorder(awsxRayRecorder); } catch (FileNotFoundException e) { LOG.error(\u0026#34;XRay config file not found\u0026#34;); } } Create the method Bean TracingFilter. This method defines a bean of type Filter using AWSXRayServletFilter.\nAWSXRayServletFilter: This filter for servlets is used to trace HTTP requests coming into and leaving the application. \u0026ldquo;productsservice\u0026rdquo; is the service name used in AWS X-Ray reporting and analysis. @Bean public Filter tracingFilter() { return new AWSXRayServletFilter(\u0026#34;productsservice\u0026#34;); } Finally, create an xray-sampling-rules.json file as described earlier. Navigate to the resources directory, create a new folder named xray, and then create a JSON file named xray-sampling-rules.json.\nConfigure the xray-sampling-rules.json file as follows:\n{ \u0026#34;version\u0026#34;: 2, \u0026#34;default\u0026#34;: { \u0026#34;fixed_target\u0026#34;: 0, \u0026#34;rate\u0026#34;: 1 }, \u0026#34;rules\u0026#34;: [ { \u0026#34;fixed_target\u0026#34;: 0, \u0026#34;rate\u0026#34;: 0, \u0026#34;url_path\u0026#34;: \u0026#34;/actuator/health\u0026#34;, \u0026#34;http_method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Load balancer health check\u0026#34; } ] } "
},
{
	"uri": "/",
	"title": "Deploy Spring Boot applications onto AWS ECS Fargate using AWS CDK.",
	"tags": [],
	"description": "",
	"content": "Deploying Spring Boot Services on AWS ECS Fargate using AWS CDK Overview In this workshop, we will create a microservice using Java 11, leveraging the Spring Boot framework, and Docker containers to build a backend application that interacts with Amazon Web Services (AWS) resources. These resources will be provisioned on AWS using the AWS Cloud Development Kit (CDK) v2, a modern way to model and configure infrastructure on AWS. AWS CDK is one of the best tools for managing infrastructure as code (IaC) on AWS.\nContent Introduction Prerequisite steps Create ECR Image Repository Create VPC and NAT Gateway Create ECS Create ECS Service Create API Gateway Create DynamoDB Table Instrumenting AWS ECS Service Clean up resources "
},
{
	"uri": "/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "This workshop will cover the following AWS resources and tools: AWS ECS: Elastic Container Service is AWS\u0026rsquo;s container orchestration service. With ECS, you can manage the execution of Docker-based microservices efficiently and at scale. With AWS Fargate, a serverless compute engine for containers from Amazon Web Services, you don\u0026rsquo;t need to provision EC2 instances, reducing the operational cost of container-based applications.\nAWS ECR: With Elastic Container Registry (ECR) from AWS, you can create private repositories to store Docker images of your microservices.\nAWS VPC: With Virtual Private Cloud (VPC) from AWS, you can secure your infrastructure with private subnets and network security policies for inbound and outbound traffic rules.\nAWS ALB: AWS Application Load Balancer allows you to balance HTTP traffic across all available application instances, and with integrated target groups, each instance can be monitored to only receive traffic if it is operating normally.\nAPI Gateway REST: With AWS API Gateway, you can protect your application\u0026rsquo;s REST APIs and perform validation checks on query string parameters and request contents.\nCloudWatch Logs: Its responsibility is to aggregate application logs and their metrics. The applications built in this workshop will log to CloudWatch Logs in JSON format using the log4j2 library. This enables us to insert parameters into the logs for use in queries in the AWS CloudWatch Logs Insights dashboard.\nCloudWatch Alarms: With alarms from CloudWatch, you can monitor unusual events from applications and AWS resources.\nDynamoDB: DynamoDB is a powerful and non-relational NoSQL database service. This workshop introduces the usage of DynamoDB enhanced client from AWS SDK v2 for Java, which is a high-level library allowing client-side class mappings with DynamoDB tables.\nSQS: SQS is a queue service that allows asynchronous communication between applications, facilitating message and event exchanges.\n"
},
{
	"uri": "/6-createservice/6.2-createectask/",
	"title": " Create ECS Task Definition",
	"tags": [],
	"description": "",
	"content": "Create ECS Task Definition Initialize a FargateTaskDefinition object within the ProductsServiceStack constructor: FargateTaskDefinition fargateTaskDefinition = new FargateTaskDefinition(this, \u0026#34;TaskDefinition\u0026#34;, FargateTaskDefinitionProps.builder() .build()); Set the family name for the task definition group: .family(\u0026#34;products-service\u0026#34;) Next, define the CPU and memory limits for the task definition: .cpu(512) .memoryLimitMiB(1024) "
},
{
	"uri": "/5-createecs/5.2-createnlb/",
	"title": " Create Network Load Balancer",
	"tags": [],
	"description": "",
	"content": "Create Network Load Balancer stack In your CDK project, create a new stack named NlbStack.java and have the NlbStack class inherit from the Stack class from the amazon.awscdk library.\nTo create the NLB stack, we need the VPC that we created earlier. Therefore, we will create a record class named NlbStackProps to pass the VPC into the NLB Stack. Add the following code outside the ClusterStack class:\nrecord NlbStackProps( Vpc vpc ){} Inside the NLB Stack, we will create Vpc Link, Network Load Balancer, and Application Load Balancer. Therefore, we need to define three attributes corresponding to them: private final VpcLink vpcLink; private final NetworkLoadBalancer networkLoadBalancer; private final ApplicationLoadBalancer applicationLoadBalancer; Next, let\u0026rsquo;s create getters for the three attributes: public VpcLink getVpcLink() { return vpcLink; } public NetworkLoadBalancer getNetworkLoadBalancer() { return networkLoadBalancer; } public ApplicationLoadBalancer getApplicationLoadBalancer() { return applicationLoadBalancer; } Create a constructor for the NlbStack class: public NlbStack(final Construct scope, final String id, final StackProps props, NlbStackProps nlbStackProps) { super(scope, id, props); } Create Network Load Balancer First, let\u0026rsquo;s create a Network Load Balancer (NLB). To do this, we need to initialize the networkLoadBalancer object within the constructor: this.networkLoadBalancer = new NetworkLoadBalancer(this, \u0026#34;Nlb\u0026#34;, NetworkLoadBalancerProps.builder() .build()); Next, set the name of the NLB to ECommerceNlb using: .loadBalancerName(\u0026#34;ECommerceNlb\u0026#34;) As shown in the design diagram, we will not expose the Network Load Balancer (NLB) and Application Load Balancer (ALB) to the internet outside of the VPC. Therefore, we will configure them as follows: .internetFacing(false) .vpc(nlbStackProps.vpc()) "
},
{
	"uri": "/7-createapigateway/7.2-createfirstmethod/",
	"title": " Create Product Resource and First Method",
	"tags": [],
	"description": "",
	"content": "Create Product Resource and First Method Create the method createProductsResource with two parameters: RestApi and ApiStackProps, and initialize it within the constructor.\nprivate void createProductsResource(RestApi restApi, ApiStackProps apiStackProps) { } ![Architect](/images/7/2/01.png?featherlight=false\u0026amp;width=60pc) 2. Create a new resource in API Gateway with the path **/products`. Using `restApi.getRoot().addResource(\u0026#34;products\u0026#34;)** will create a new sub-resource with the path **/products** from the root of the API (`restApi`). ```java //products Resource productsResource = restApi.getRoot().addResource(\u0026#34;products\u0026#34;); Add a GET method to productsResource using the addMethod method. productsResource.addMethod(\u0026#34;GET\u0026#34;); Next, we define an Integration to handle GET requests to the endpoint /products. productsResource.addMethod(\u0026#34;GET\u0026#34;, new Integration( IntegrationProps.builder() .build())); Then, specify the Integration type as HTTP_PROXY, which means using an HTTP proxy to forward requests, and choose the Integration method type as GET. .type(IntegrationType.HTTP_PROXY) .integrationHttpMethod(\u0026#34;GET\u0026#34;) Set the URI of the backend that the API Gateway will forward requests to. Here, the DNS name of the Network Load Balancer is used to construct the URL, along with port 8081 and the API path /api/products being called. .uri(\u0026#34;http://\u0026#34; + apiStackProps.networkLoadBalancer().getLoadBalancerDnsName() + \u0026#34;:8081/api/products\u0026#34;) Next, use options to further configure the IntegrationOptions. .options(IntegrationOptions.builder() .build()) Specify the VpcLink to identify which VPC connection will be used for the Integration method and define the connection type as VPC_LINK, meaning connecting through an AWS VPC. .vpcLink(apiStackProps.vpcLink()) .connectionType(ConnectionType.VPC_LINK) "
},
{
	"uri": "/8-createdynamodb/8.2-post/",
	"title": " Create REST operation to create a new Product",
	"tags": [],
	"description": "",
	"content": "Create REST Operation to Create a New Product Open the file ApiStack.java. Within the createProductsResource method, use the addMethod function to create a PUT method for the productsResource resource. productsResource.addMethod(\u0026#34;POST\u0026#34;); Next, we will define an Integration to handle POST requests to the endpoint /products. This part is similar to the GET integration, but we just need to specify integrationHttpMethod(\u0026ldquo;POST\u0026rdquo;). productsResource.addMethod(\u0026#34;POST\u0026#34;, new Integration( IntegrationProps.builder() .type(IntegrationType.HTTP_PROXY) .integrationHttpMethod(\u0026#34;POST\u0026#34;) .uri(\u0026#34;http://\u0026#34; + apiStackProps.networkLoadBalancer().getLoadBalancerDnsName() + \u0026#34;:8081/api/products\u0026#34;) .options(IntegrationOptions.builder() .vpcLink(apiStackProps.vpcLink()) .connectionType(ConnectionType.VPC_LINK) .build()) .build())); "
},
{
	"uri": "/2-prerequiste/2.2-createspingbootproject/",
	"title": " Creating a Spring Boot Project",
	"tags": [],
	"description": "",
	"content": "Creating a Spring Boot Project Visit start.spring.io.\nChoose the programming language and framework version:\nFor Project, select Gradle - Groovy. For Language, choose Java. For Spring Boot version, select 3.2.4. Configure Project Metadata:\nSet Group to com.firstcloudjourney. Set Artifact to productsservice. Other fields will be automatically filled. Choose Java version as 21. Add Dependencies:\nClick ADD DEPENDENCIES to open a pop-up. Add Spring Web and Spring Boot Actuator packages. Generate the Spring Boot Project:\nClick GENERATE to download the created project. "
},
{
	"uri": "/9-intrumentingecs/9.2-createxrayinspector/",
	"title": " Creating X-Ray Inspector",
	"tags": [],
	"description": "",
	"content": "Creating X-Ray Inspector First, to measure methods, add the @XRayEnabled annotation to the ProductRepository and ProductsController files.\nIn the config directory, create a new file named XRayInspector.\nAdd two annotations to the XRayInspector class:\n@Aspect: This is a Spring AOP annotation that indicates the class contains cross-cutting concerns, meaning behaviors that can affect or be applied across different classes or methods. In this case, it involves adding monitoring information from AWS X-Ray. @Component: This Spring Framework annotation marks the class as a \u0026ldquo;component,\u0026rdquo; allowing Spring to automatically detect and manage it as a bean in the ApplicationContext. Have the XRayInspector class inherit from BaseAbstractXRayInterceptor, an abstract class used to create interceptors for AWS X-Ray, where methods can be overridden to customize the behavior of subsegments within AWS X-Ray.\n@Aspect @Component public class XRayInspector extends BaseAbstractXRayInterceptor { @Override protected void xrayEnabledClasses() { // Implement custom behavior here } } Create the generateMetadata() method. This method overrides the method from the parent class (BaseAbstractXRayInterceptor). Its purpose is to generate metadata for a subsegment of AWS X-Ray based on the ongoing join point. ProceedingJoinPoint is a concept in AOP representing a point of execution where an interception can occur, and a Subsegment is part of a trace in AWS X-Ray, allowing additional information to be collected. In this case, the method simply calls the parent class method using super.generateMetadata(). @Override protected Map\u0026lt;String, Map\u0026lt;String, Object\u0026gt;\u0026gt; generateMetadata( ProceedingJoinPoint proceedingJoinPoint, Subsegment subsegment ) { return super.generateMetadata(proceedingJoinPoint, subsegment); } The xrayEnabledClasses() method is annotated with @Pointcut. This annotation specifies a pointcut expression in Spring AOP, describing where an advice should be applied. In this case, the pointcut expression @within(com.amazonaws.xray.spring.aop.XRayEnabled) indicates that the advice will be applied to any class annotated with @XRayEnabled provided by com.amazonaws.xray.spring.aop. The method itself has no content inside, as it is used solely to define the location where the advice should be applied. @Override @Pointcut(\u0026#34;@within(com.amazonaws.xray.spring.aop.XRayEnabled)\u0026#34;) protected void xrayEnabledClasses() {} Add X-Ray interceptor to the DynamoDB client To add an X-Ray interceptor to the DynamoDB client, open the DynamoDBConfig file and modify the dynamoDbAsyncClient configuration as follows: .overrideConfiguration(ClientOverrideConfiguration.builder() .addExecutionInterceptor(new TracingInterceptor()) .build()) Finally, add @EnableAspectJAutoProxy to ProductsserviceApplication.\n"
},
{
	"uri": "/4-createvpc/4.2-orgaizestack/",
	"title": " Organize and Deploy VPC Stack using AWS CDK",
	"tags": [],
	"description": "",
	"content": "Organize VPC stack in CDK project Open the root file Fcj2024CdkApp.\nCreate a VPC Stack with the ID Vpc using the following code:\nVpcStack vpcStack = new VpcStack(app, \u0026#34;Vpc\u0026#34;, StackProps.builder() .build()); Add environment and Tags\nDeploy VPC stack Open a terminal and run the command cdk list to view the list of available tasks. Here, you will see Ecr and Vpc.\nNext, run cdk deploy --all to deploy all stacks. When prompted about changeset execution policy, enter y.\nReview the changes during deployment. You will see that CDK recognizes that the ECR has not changed and that a new stack for VPC is being created.\nCheck created resources on AWS Console Access the AWS Console, navigate to the VPC interface, and select Your VPCs. You should see ECommerceVPC listed.\nSimilarly, check for Subnets, NAT Gateways, Security Groups, etc.\n"
},
{
	"uri": "/3-createecr/3.2-organizestack/",
	"title": " Organize CDK Stack in CDK Project",
	"tags": [],
	"description": "",
	"content": "Organize CDK Stack in CDK Project Open the root file Fcj2024CdkApp. Create an ECR Stack using the following code snippet:\nEcrStack ecrStack = new EcrStack(app, \u0026#34;Ecr\u0026#34;, StackProps.builder().build()); Create an Environment using the following code:\nEnvironment environment = Environment.builder() .account(\u0026#34;your_account_id\u0026#34;) .region(\u0026#34;ap-southeast-1\u0026#34;) .build(); Replace your_account_id with your AWS account ID. Use ap-southeast-1 as the desired AWS region for resource creation. Add the Environment to the ECRStack using the following code:\n.env(environment) Create properties infraTags for Tags:\nMap\u0026lt;String, String\u0026gt; infraTags = new HashMap\u0026lt;\u0026gt;(); infraTags.put(\u0026#34;team\u0026#34;, \u0026#34;FirstCloudJourney\u0026#34;); infraTags.put(\u0026#34;cost\u0026#34;, \u0026#34;ECommerceInfra\u0026#34;); Apply Tags to the ECRStack:\n.tags(infraTags) Check the stacks that CDK will create for CloudFormation using the command:\ncdk list Here, CDK shows that only one stack (Ecr) will be created. To prepare the deployment environment for CDK applications on AWS, including creating necessary resources for deployment and managing CDK applications effectively on the AWS platform, run the command:\ncdk bootstrap --profile default To view the resources created after running cdk bootstrap \u0026ndash;profile default, access the AWS console and navigate to CloudFormation.\nIn the CloudFormation interface, you can see a CDKToolkit stack has been created.\nSelect CDKToolkit and then choose the Resources tab to view the created resources.\n"
},
{
	"uri": "/2-prerequiste/",
	"title": "Preparation Steps",
	"tags": [],
	"description": "",
	"content": "Preparation Steps Java Development Kit (JDK)\nFirstly, we need to install the Java Development Kit (JDK). In this workshop, we will use JDK 21 LTS. You can download it here. Next, we need to install Maven. You can install it following the instructions here. NodeJS\nTo install the AWS CDK CLI, we need to install NodeJS. Visit this link to download the latest LTS version.\nVerify if NodeJS is installed correctly by running the following command in the terminal:\nnode -v This command will display the installed NodeJS version:\nv18.15.0 Check the installed NPM version by running the following command in the terminal:\nnpm -v This command will display the installed NPM version:\n9.6.2 AWS CLI\nVisit this link and download the latest version of AWS CLI.\nAfter installation is complete, open a terminal and verify the installed AWS CLI version using the following command:\naws --version AWS CDK\nAWS Cloud Development Kit, or AWS CDK, will be used to build infrastructure-as-code responsible for creating the application infrastructure using AWS services.\nAfter installing the above packages, run the following command in your terminal window to install AWS CDK:\nnpm install -g aws-cdk Verify if CDK is installed correctly by running the following command in the terminal: cdk --version Postman\nPostman is a very useful free application. By using it, you can send requests to the applications developed in this workshop, whether they are running on your computer or deployed on your AWS account. Download Postman based on the instructions. IntelliJ IDEA Community Edition\nThe IDE that will be used is IntelliJ IDEA Community Edition, from JetBrains. This is one of the most modern IDEs for development in Java and other programming languages. Download IntelliJ IDEA Community Edition from this link. Docker Desktop\nDocker Desktop will be used to create Docker images of all applications to be built in this workshop before uploading the image to AWS. Download Docker via this link. "
},
{
	"uri": "/9-intrumentingecs/9.3-addxraytotask/",
	"title": " Adding X-Ray Sidecar to ProductsServices Task Definition",
	"tags": [],
	"description": "",
	"content": "Adding an X-Ray Sidecar Container to ProductsServices Task Definition Open the FCJ2024_SDK project and navigate to the ProductsServiceStack.java file.\nAdd environment variables for X-Ray as follows:\nenvVariables.put(\u0026#34;AWS_XRAY_DAEMON_ADDRESS\u0026#34;, \u0026#34;0.0.0.0:2000\u0026#34;); envVariables.put(\u0026#34;AWS_XRAY_CONTEXT_MISSING\u0026#34;, \u0026#34;IGNORE_ERROR\u0026#34;); envVariables.put(\u0026#34;AWS_XRAY_TRACING_NAME\u0026#34;, \u0026#34;productsservice\u0026#34;); In the fargateTaskDefinition.addContainer section, add CPU as 348 and memory as 896 .cpu(384) .memoryLimitMiB(896) Next, add a sidecar container (X-Ray) to the ProductsServices task definition as follows: fargateTaskDefinition.addContainer(\u0026#34;xray\u0026#34;, ContainerDefinitionOptions.builder() .image(ContainerImage.fromRegistry(\u0026#34;public.ecr.aws/xray/aws-xray-daemon:latest\u0026#34;)) .containerName(\u0026#34;XRayProductsService\u0026#34;) .logging(new AwsLogDriver(AwsLogDriverProps.builder() .logGroup(new LogGroup(this, \u0026#34;XRayLogGroup\u0026#34;, LogGroupProps.builder() .logGroupName(\u0026#34;XRayProductsService\u0026#34;) .removalPolicy(RemovalPolicy.DESTROY) .retention(RetentionDays.ONE_MONTH) .build())) .streamPrefix(\u0026#34;XRayProductsService\u0026#34;) .build())) .portMappings(Collections.singletonList(PortMapping.builder() .containerPort(2000) .protocol(Protocol.UDP) .build())) .cpu(128) .memoryLimitMiB(128) .build()); Cấp quyền để cho phép các containers trong task có khả năng gửi dữ liệu đến AWS X-Ray mà không cần quyền đọc hoặc quản lý các tài nguyên X-Ray. Điều này giúp việc theo dõi và phân tích hiệu suất của ứng dụng được thực hiện một cách an toàn và hiệu quả. fargateTaskDefinition.getTaskRole().addManagedPolicy(ManagedPolicy.fromAwsManagedPolicyName(\u0026#34;AWSXrayWriteOnlyAccess\u0026#34;)); "
},
{
	"uri": "/3-createecr/",
	"title": " Create AWS ECR Image Repository using AWS CDK",
	"tags": [],
	"description": "",
	"content": "In this section, we will learn how to create a stack to deploy Amazon ECR on AWS.\n"
},
{
	"uri": "/8-createdynamodb/8.3-put/",
	"title": " Create REST Operation to Update Product by ID",
	"tags": [],
	"description": "",
	"content": "Create REST Operation to Update Product by ID Create a new Resource object by calling the addResource(\u0026quot;{id}\u0026quot;) method on the productsResource object. This is part of configuring the routing of the API Gateway, allowing for handling requests to /{id}. Resource productIdResource = productsResource.addResource(\u0026#34;{id}\u0026#34;); Add a new Method to the productIdResource by using the addMethod(\u0026ldquo;PUT\u0026rdquo;) method. productIdResource.addMethod(\u0026#34;PUT\u0026#34;); Next, we need to configure an Integration for the Method. We can reuse the integration from the previous section and change the integrationHttpMethod to PUT for the HTTP method. productIdResource.addMethod(\u0026#34;PUT\u0026#34;, new Integration( IntegrationProps.builder() .type(IntegrationType.HTTP_PROXY) .integrationHttpMethod(\u0026#34;PUT\u0026#34;) .uri(\u0026#34;http://\u0026#34; + apiStackProps.networkLoadBalancer().getLoadBalancerDnsName() + \u0026#34;:8080/api/products/{id}\u0026#34;) .options(IntegrationOptions.builder() .vpcLink(apiStackProps.vpcLink()) .connectionType(ConnectionType.VPC_LINK) .build()) .build())); Then, we need to add requestParameters under connectionType(). .requestParameters() The requestParameters method requires a data type of Map\u0026lt;String, String\u0026gt;. Let\u0026rsquo;s define it.\nFirst, create a Map named productIdIntegrationParameters: Within this map, use \u0026ldquo;integration.request.path.id\u0026rdquo; as a key and assign its value to \u0026ldquo;method.request.path.id\u0026rdquo;. This configuration sets up API Gateway to extract the id value from the incoming request path sent by the client and pass it to the backend with the same parameter name in the backend\u0026rsquo;s request path. Map\u0026lt;String, String\u0026gt; productIdIntegrationParameters = new HashMap\u0026lt;\u0026gt;(); productIdIntegrationParameters.put(\u0026#34;integration.request.path.id\u0026#34;, \u0026#34;method.request.path.id\u0026#34;); Use MethodOptions.builder().requestParameters(productIdMethodParameters).build() to configure the method parameters, in this case productIdMethodParameters, which specifies that path.id is required when sending a request.\nFirst, create a Map named productIdMethodParameters to ensure that ID is required when sending a request: Map\u0026lt;String, Boolean\u0026gt; productIdMethodParameters = new HashMap\u0026lt;\u0026gt;(); productIdMethodParameters.put(\u0026#34;method.request.path.id\u0026#34;, true); Then, include productIdMethodParameters in methodOptions MethodOptions.builder() .requestParameters(productIdMethodParameters) .build() "
},
{
	"uri": "/6-createservice/6.3-createsericelogdriver/",
	"title": " Create Service Log Driver",
	"tags": [],
	"description": "",
	"content": "Create Service Log Driver During the development of a Spring Boot application, we need logging for debugging the application. Therefore, we will use CloudWatch Log Groups.\nTo create a log group, first initialize an AwsLogDriver object within the constructor:\nAwsLogDriver logDriver = new AwsLogDriver(AwsLogDriverProps.builder() .build()); Initialize a LogGroup object within the AwsLogDriver: .logGroup(new LogGroup(this, \u0026#34;LogGroup\u0026#34;, LogGroupProps.builder() .build())) Next, we need to add the necessary properties for the LogGroup: Set the log group name to ProductsService: .logGroupName(\u0026#34;ProductsService\u0026#34;) Configure the log group to be deleted when the Stack is deleted: .removalPolicy(RemovalPolicy.DESTROY) Finally, specify how long AWS should retain these logs. Let\u0026rsquo;s retain them for one month: .retention(RetentionDays.ONE_MONTH) Finally, we need to set a prefix for our log files: .streamPrefix(\u0026#34;ProductsService\u0026#34;) "
},
{
	"uri": "/5-createecs/5.3-createvpclink/",
	"title": " Create VPC Link",
	"tags": [],
	"description": "",
	"content": "Create VPC Link To create a VPC Link, we need to initialize the vpcLink object that was previously declared: this.vpcLink = new VpcLink(this, \u0026#34;VpcLink\u0026#34;, VpcLinkProps.builder() .build()); Next, we will connect the VPC Link to the Network Load Balancer (NLB) by setting the NLB as the target for the VPC Link: .targets(Collections.singletonList(this.networkLoadBalancer)) "
},
{
	"uri": "/3-createecr/3.3-implementstack/",
	"title": " Deploy Stack to AWS ECR",
	"tags": [],
	"description": "",
	"content": "Deploy Stack to AWS ECR To deploy the stack to AWS ECR, run the following command:\ncdk deploy Ecr --profile default During the resource creation process, if prompted with security policy questions, enter y to proceed.\nThe creation of the ECR repository is successful.\nAccess the AWS console, navigate to ECR, and select Elastic Container Registry.\nYou will see that the productsservice repository has been successfully created.\n"
},
{
	"uri": "/2-prerequiste/2.3-setupintellijidea/",
	"title": " Setting Up IntelliJ IDEA",
	"tags": [],
	"description": "",
	"content": "Setting Up IntelliJ IDEA Open IntelliJ IDEA and navigate to the Spring Boot project you just created.\nConfigure the project:\nRight-click on the project and select Open Module Settings. Under Project Settings, ensure that your project has SDK set to 21 and language level set to 21.\nUnder Platform Settings, ensure that your platform SDK is set to 21.\nRunning the Spring Boot Project Open the file application.properties and add server.port=8081 to configure the project to run on port 8081.\nClick on the Run icon to run the project. You can see the project running on port 8081.\nTesting the Project with Postman Create an HTTP GET request with the URL http://localhost:8081/actuator/health to test.\nThe response should show \u0026ldquo;status\u0026rdquo;: \u0026ldquo;UP\u0026rdquo; indicating that the project is running normally. Adding the Log4j2 Library Open the build.gradle file:\nIn the dependencies section, add the Log4j2 library with the following code: implementation \u0026#39;org.springframework.boot:spring-boot-starter-log4j2\u0026#39; Add configurations: configurations { configureEach { exclude group: \u0026#39;org.springframework.boot\u0026#39;, module: \u0026#39;spring-boot-starter-logging\u0026#39; exclude group: \u0026#39;commons-logging\u0026#39;, module: \u0026#39;commons-logging\u0026#39; } } Creating a Controller Inside the com.firstcloudjourney.productsservice directory, create a folder named products.\nInside the products folder, create a directory named controllers and create a file named ProductsController.java inside the controllers directory.\nCopy and paste the following code into ProductsController.java:\nimport org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController @RequestMapping(\u0026#34;/api/products\u0026#34;) public class ProductsController { private static final Logger LOG = LogManager.getLogger(ProductsController.class); @GetMapping public String getAllProducts() { LOG.info(\u0026#34;Get all products\u0026#34;); return \u0026#34;All products\u0026#34;; } } Run the project and test with Postman by creating an HTTP GET request with the URL http://localhost:8081/api/products.\nCheck the logs returned in the terminal when making the HTTP GET request.\n"
},
{
	"uri": "/7-createapigateway/7.3-organizestack/",
	"title": "Tổ chức Stack",
	"tags": [],
	"description": "",
	"content": "Tổ chức Stack Mở file root Fcj2024CdkApp Tạo ApiStack với id là Api ApiStack apiStack = new ApiStack(app, \u0026#34;Api\u0026#34;, StackProps.builder() .build(), new ApiStackProps( nlbStack.getNetworkLoadBalancer(), nlbStack.getVpcLink())); Add environment and tags to the ApiStack. .env(environment) .tags(infraTags) Add a dependency to ensure that the Network Load Balancer (NLB) is created before the API Gateway. apiStack.addDependency(nlbStack); Resource Check In the AWS console interface, navigate to API Gateway.\nWithin the API Gateway interface, select APIs to find an API named ECommerceAPI that has been created.\nChoose ECommerceAPI and then select GET.\nTest API on Postman Within the ECommerceAPI interface, navigate to Stages and copy the Invoke URL.\nOpen Postman and create a GET request with the path Invoke URL/product.\n"
},
{
	"uri": "/6-createservice/6.4-addservicetotask/",
	"title": " Add Container Service to Task Definition",
	"tags": [],
	"description": "",
	"content": "Add Container Service to Task Definition To add a container, use the addContainer method of the previously initialized fargateTaskDefinition: fargateTaskDefinition.addContainer() Specify the ID as ProductsServiceContainer and create ContainerDefinitionOptions: fargateTaskDefinition.addContainer(\u0026#34;ProductsServiceContainer\u0026#34;, ContainerDefinitionOptions.builder() .build()); Thêm image từ ECR Repository với phiên bản 1.0.0 chúng ta đã tạo trước đó\nAdd an image from the ECR Repository with version 1.0.0 that we created earlier:\n.image(ContainerImage.fromEcrRepository(productsServiceProps.repository(), \u0026#34;1.0.0\u0026#34;)) Next, set the name for the container and add the previously created logDriver: .containerName(\u0026#34;productsService\u0026#34;) .logging(logDriver) Since our application uses port 8081, we need to add port mappings for the container service: .portMappings(Collections.singletonList(PortMapping.builder() .containerPort(8081) .protocol(Protocol.TCP) .build())) Next, we need to create environment variables. Its value is a Map\u0026lt;String, String\u0026gt;: First, declare a variable envVariables:\nMap\u0026lt;String, String\u0026gt; envVariables = new HashMap\u0026lt;\u0026gt;(); envVariables.put(\u0026#34;SERVER_PORT\u0026#34;, \u0026#34;8081\u0026#34;); Then, add environment variables to the service container:\n.environment(envVariables) "
},
{
	"uri": "/5-createecs/5.4-createalb/",
	"title": " Create Application Load Balancer",
	"tags": [],
	"description": "",
	"content": "Create Application Load Balancer First, let\u0026rsquo;s create an Application Load Balancer (ALB). To create the ALB, we need to initialize the applicationLoadBalancer object within the constructor: this.applicationLoadBalancer = new ApplicationLoadBalancer(this, \u0026#34;Alb\u0026#34;, ApplicationLoadBalancerProps.builder() .build()); Next, set the name for the Application Load Balancer (ALB) to ECommerceAlb using: .loadBalancerName(\u0026#34;ECommerceAlb\u0026#34;) As mentioned earlier, we will not expose the Application Load Balancer (ALB) and Network Load Balancer (NLB) to the internet outside of the VPC. Therefore, we will configure them as follows: .internetFacing(false) .vpc(nlbStackProps.vpc()) "
},
{
	"uri": "/2-prerequiste/2.4-createdockerfile/",
	"title": " Create Dockerfile and Generate Docker Image",
	"tags": [],
	"description": "",
	"content": "Create Task First, you need to create a task in the build.gradle file by copying the following code block: tasks.register(\u0026#34;unpack\u0026#34;, Copy) { dependsOn bootJar from(zipTree(tasks.bootJar.outputs.files.singleFile)) into(\u0026#34;build/libs\u0026#34;) } This code defines a Gradle task named \u0026ldquo;unpack\u0026rdquo; that copies files from a ZIP archive generated by the \u0026ldquo;bootJar\u0026rdquo; task and extracts them into the \u0026ldquo;build/libs\u0026rdquo; directory.\nCreate .dockerignore File Create a .dockerignore file to specify files and directories that Docker should ignore when building a Docker image from your project components. Copy the code below: .git .gitignore .dockerignore .gradle .idea Dockerfile README.md Create file Dockerfile Create a Dockerfile and copy the code below: FROM eclipse-temurin:21-jdk-alpine VOLUME /tmp ARG DEPENDENCY=build/libs COPY ${DEPENDENCY}/BOOT-INF/lib /app/lib COPY ${DEPENDENCY}/META-INF /app/META-INF COPY ${DEPENDENCY}/BOOT-INF/classes /app EXPOSE 8081 ENTRYPOINT [\u0026#34;java\u0026#34;, \u0026#34;-cp\u0026#34;, \u0026#34;app:app/lib/*\u0026#34;, \u0026#34;com.firstcloudjourney.productsservice.ProductsserviceApplication\u0026#34;] Generate Docker Image Next, let\u0026rsquo;s configure IntelliJ to generate a Docker image: Click on the Run icon and select New Run Configuration. A popup will appear where we\u0026rsquo;ll configure as follows: For Image Tag, enter productsservice:1.0.0. Click Modify Options, then select Build options. Once Build options appears, enter --platform linux/amd64. Next, we need to configure Before Launch: Click the + icon and select Run Gradle Task. Then a popup will appear as shown below: In the popup for Select Gradle Task: For Gradle project, choose productsservice. For Task, select the unpack task that we added earlier. Click OK. After returning to the Edit Configuration popup, click Apply. Build Application using BootJar Next, let\u0026rsquo;s build the application using bootJar from Gradle: Click on the Gradle icon. Choose Tasks, then build, and finally click bootJar to build the application. Check the built application file located in build/libs. Generate Docker Image Now, let\u0026rsquo;s create a Docker image from the built application: Click on the Run icon on the Dockerfile and choose Build image for \u0026lsquo;DockerFile\u0026rsquo;. Make sure you have Docker Desktop running to successfully build the image.\nAfter successfully creating the image, you should see productsservice:1.0.0 generated. "
},
{
	"uri": "/8-createdynamodb/8.4-getbyid/",
	"title": " Create REST Operation to GET Product by ID",
	"tags": [],
	"description": "",
	"content": "Create REST Operation to GET Product by ID We can quickly create a GET method by ID by copying the previously created PUT method and replacing PUT with GET. // GET /products/{id} productIdResource.addMethod(\u0026#34;GET\u0026#34;, new Integration( IntegrationProps.builder() .type(IntegrationType.HTTP_PROXY) .integrationHttpMethod(\u0026#34;GET\u0026#34;) .uri(\u0026#34;http://\u0026#34; + apiStackProps.networkLoadBalancer().getLoadBalancerDnsName() + \u0026#34;:8080/api/products/{id}\u0026#34;) .options(IntegrationOptions.builder() .vpcLink(apiStackProps.vpcLink()) .connectionType(ConnectionType.VPC_LINK) .requestParameters(productIdIntegrationParameters) .build()) .build()), MethodOptions.builder() .requestParameters(productIdMethodParameters) .build()); "
},
{
	"uri": "/4-createvpc/",
	"title": " Create VPC and NAT Gateway using AWS CDK",
	"tags": [],
	"description": "",
	"content": "In this section, we will create a VPC and NAT Gateway using AWS CDK.\n"
},
{
	"uri": "/3-createecr/3.4-pushimage/",
	"title": " Push Docker image to ECR",
	"tags": [],
	"description": "",
	"content": "Push Docker image to ECR repository Ensure you have installed the AWS Toolkit. If not, go to IntelliJ IDEA Settings, select Plugins, and search for AWS Toolkit to install it.\nClick on the AWS Toolkit icon on the right side of IntelliJ IDEA.\nSelect profile and region:\nFor Profile, choose default. For Region, choose ap-southeast-1. Open the Explorer to view all AWS Toolkit-supported services, then select ECR.\nRight-click on the productsservice repository and choose Push to Repository\u0026hellip; to push the Docker image.\nIn the Push to ECR popup:\nFor Local Image, select productsservice:1.0.0. For ECR Repository, choose productsservice. For Remote Tag, enter 1.0.0. Finally, click Push. Check the image on ECR In the AWS Management Console, navigate to ECR.\nSelect the productsservice repository to view the Docker image version 1.0.0 that has been pushed.\n"
},
{
	"uri": "/9-intrumentingecs/9.4-testimplement/",
	"title": "Testing the implementation",
	"tags": [],
	"description": "",
	"content": "Testing the implementation Switch back to the productsservice project. Package the project into a JAR using Gradle. Open the Dockerfile and create an image tag named productsservice:1.3.0. Once the Docker image build is complete, push it to the ECR Repository with a remote tag of 1.3.0. Return to the FCJ2024_CDK project and update the image tag in fargateTaskDefinition.addContainer to 1.3.0. Deploy the service using the following command: cdk deploy --all --require-approval never After completing the deployment, access the ECS interface and select Task. Then choose any task from the running tasks. In the selected task interface, you can see a sidecar container named XRayProductsService running alongside the productsService container. Next, we will test the API in Postman to measure the AWS ECS service using AWS X-Ray. Access the CloudWatch interface and select Trace Map to view the request path. Finally, to view ECS measurement information, select the ECS icon on the trace map. Similarly, with DynamoDB. "
},
{
	"uri": "/6-createservice/6.5-addlistenteralb/",
	"title": " Add Listener to Application Load Balancer",
	"tags": [],
	"description": "",
	"content": "Add Listener to Application Load Balancer Initialize an ApplicationListener: ApplicationListener applicationListener = productsServiceProps.applicationLoadBalancer(); Add a listener with the ID ProductsServiceAlbListener and initialize ApplicationListenerProps: .addListener(\u0026#34;ProductsServiceAlbListener\u0026#34;, ApplicationListenerProps.builder() .build()); Next, configure the ALB listener on port 8081 using the HTTP protocol: .port(8081) .protocol(ApplicationProtocol.HTTP) Finally, add the applicationListener to the Application Load Balancer: .loadBalancer(productsServiceProps.applicationLoadBalancer()) "
},
{
	"uri": "/8-createdynamodb/8.5-deletebyid/",
	"title": " Create REST Operation to DELETE Product by ID",
	"tags": [],
	"description": "",
	"content": "Create REST Operation to DELETE Product by ID We can quickly create a DELETE method by ID by copying the previously created PUT method and replacing PUT with DELETE. productIdResource.addMethod(\u0026#34;DELETE\u0026#34;, new Integration( IntegrationProps.builder() .type(IntegrationType.HTTP_PROXY) .integrationHttpMethod(\u0026#34;DELETE\u0026#34;) .uri(\u0026#34;http://\u0026#34; + apiStackProps.networkLoadBalancer().getLoadBalancerDnsName() + \u0026#34;:8080/api/products/{id}\u0026#34;) .options(IntegrationOptions.builder() .vpcLink(apiStackProps.vpcLink()) .connectionType(ConnectionType.VPC_LINK) .requestParameters(productIdIntegrationParameters) .build()) .build()), MethodOptions.builder() .requestParameters(productIdMethodParameters) .build()); "
},
{
	"uri": "/5-createecs/5.5-organizeanddeploystack/",
	"title": " Organize and Deploy NLB Stack",
	"tags": [],
	"description": "",
	"content": "Organize and Deploy NLB Stack Open the root file Fcj2024CdkApp.\nCreate an NLB Stack with the ID Nlb using the following code:\nNlbStack nlbStack = new NlbStack(app, \u0026#34;Nlb\u0026#34;, StackProps.builder() .build()); Pass the previously created VPC to the ClusterStackProps of the ECS stack: new ClusterStackProps(vpcStack.getVpc()) Add environmen and Tags for NLB Stack .env(environment) .tags(infraTags) Because the Network Load Balancer (NLB) requires a VPC to be created, let\u0026rsquo;s add a dependency to ensure that the VPC is created before the NLB: nlbStack.addDependency(vpcStack); Deploy NLB using AWS CDK Deploy the Network Load Balancer (NLB) using AWS CDK: cdk deploy --all --require-approval never Check AWS Resources Created In the AWS Management Console, navigate to EC2.\nIn the EC2 interface, select Load Balancers to view the created Network Load Balancer (NLB) and Application Load Balancer (ALB).\nIn the EC2 interface, enter \u0026ldquo;API Gateway\u0026rdquo; into the search bar and select API Gateway from the results.\nIn the API Gateway interface, select VPC links to view the successfully created VPC link.\n"
},
{
	"uri": "/2-prerequiste/2.5-rundockerlocal/",
	"title": " Run Docker Image on Local Machine",
	"tags": [],
	"description": "",
	"content": "Run Docker Image on Local Machine Right-click on the productsservice:1.0.0 image we created earlier and select Create Container. A Docker image configuration popup will appear. Choose Run and the terminal will execute. Configure the Docker container:\nIn the Services interface, select the Dashboard tab and then click Add under Ports. A Port bindings popup will appear. Click Modify Options, then select Host IP. Enter 0.0.0.0 for the Host IP. Similarly, configure Host Port as 8081 and Protocol as TCP. For \u0026ndash;publish, enter 8081 and select Recreate container. Test Application on Postman Run the project and test on Postman by creating an HTTP GET request with the URL http://localhost:8081/api/products. "
},
{
	"uri": "/5-createecs/",
	"title": "Create ECS using AWS CDK",
	"tags": [],
	"description": "",
	"content": "In this section, we will create an ECS cluster, ECS infrastructure, and ECS service. "
},
{
	"uri": "/8-createdynamodb/8.6-configdynamodb/",
	"title": " Configure DynamoDB",
	"tags": [],
	"description": "",
	"content": "Add AWS SDK Dependencies to ProductsService Project Open the build.gradle file and add AWS SDK dependencies as follows: implementation(platform(\u0026#34;software.amazon.awssdk:bom:2.21.15\u0026#34;)) implementation(\u0026#34;software.amazon.awssdk:dynamodb\u0026#34;) implementation(\u0026#34;software.amazon.awssdk:dynamodb-enhanced\u0026#34;) Create a Products Model to Represent it in the New DynamoDB Table Inside the products directory, create a new directory named Models and then create a new Java file named Product.java.\nDefine the model using the following code snippet:\n@DynamoDbBean public class Product { private String id; private String productName; private String code; private float price; private String model; private String productUrl; @DynamoDbPartitionKey public String getId() { return id; } public void setId(String id) { this.id = id; } public String getProductName() { return productName; } public void setProductName(String productName) { this.productName = productName; } public String getCode() { return code; } public void setCode(String code) { this.code = code; } public float getPrice() { return price; } public void setPrice(float price) { this.price = price; } public String getModel() { return model; } public void setModel(String model) { this.model = model; } public String getProductUrl() { return productUrl; } public void setProductUrl(String productUrl) { this.productUrl = productUrl; } } Tạo DynamoDB config class Create DynamoDB Configuration Class Create a new folder named config, and then create a new file named DynamoDBConfig.java inside this folder. Add the @Configuration annotation from Spring, which specifies that this class contains bean definitions for the Spring container. This class serves as a configuration source. @Configuration public class DynamoDBConfig { } Create an instance variable to store the AWS region information, where its value is injected from the aws.region property in the application.properties configuration file. @Value(\u0026#34;${aws.region}\u0026#34;) private String awsRegion; Open the application.properties file to configure the region as ap-southeast-1 (Singapore). Add the following line to application.properties: aws.region=ap-southeast-1 Return to the DynamoDBConfig file and create a method named dynamoDbAsyncClient to instantiate and configure a DynamoDbAsyncClient, which is an asynchronous client for interacting with AWS DynamoDB. @Bean @Primary public DynamoDbAsyncClient dynamoDbAsyncClient() { return DynamoDbAsyncClient.builder() .credentialsProvider(DefaultCredentialsProvider.create()) .region(Region.of(awsRegion)) .overrideConfiguration(ClientOverrideConfiguration.builder() .addExecutionInterceptor(new TracingInterceptor()) .build()) .build(); } Add a method dynamoDbEnhancedAsyncClient to instantiate and configure a DynamoDbEnhancedAsyncClient, which is an enhanced version of the asynchronous client for working with AWS DynamoDB. @Bean @Primary public DynamoDbEnhancedAsyncClient dynamoDbEnhancedAsyncClient() { return DynamoDbEnhancedAsyncClient.builder() .dynamoDbClient(dynamoDbAsyncClient()) .build(); } The DynamoDbEnhancedAsyncClient provides simpler and more user-friendly APIs compared to the regular DynamoDbAsyncClient, focusing on working with tables and data models in DynamoDB in a more abstracted and detailed way. Using this enhanced client reduces some complexity when interacting with DynamoDB, especially when performing CRUD (Create, Read, Update, Delete) operations on data.\n"
},
{
	"uri": "/6-createservice/6.6-createfagateservice/",
	"title": " Create AWS Fargate Service",
	"tags": [],
	"description": "",
	"content": "Create AWS Fargate Service Initialize a FargateService within the ProductsServiceStack constructor with the ID ProductsService: FargateService fargateService = new FargateService(this, \u0026#34;ProductsService\u0026#34;, FargateServiceProps.builder() .build()); Set the service name to ProductsService: .serviceName(\u0026#34;ProductsService\u0026#34;) Next, specify the cluster that was created earlier to create the Fargate service: .cluster(productsServiceProps.cluster()) In addition to the cluster, we need to specify the task definition to use for creating the Fargate service. We will use the fargateTaskDefinition that was created earlier: .taskDefinition(fargateTaskDefinition) Next, specify the desired number of instances to use. In this workshop, we will use 2 instances: .desiredCount(2) Next, to keep the Fargate tasks in a private subnet and allow outbound connectivity through a NAT Gateway without assigning a public IP: .assignPublicIp(false) Additionally, if you did not create a NAT Gateway in the VPC creation phase, you can enable public IP assignment for the Fargate service: .assignPublicIp(true) Đừng làm trong môi trường production\nECS service của chúng ta cần permission để pull image từ ECR repository. Vì vậy chúng ta cần phải cấp quyền như sau productsServiceProps.repository().grantPull(Objects.requireNonNull(fargateTaskDefinition.getExecutionRole())); Finally, another important aspect is defining that our service accepts requests on HTTP port 8081: fargateService.getConnections().getSecurityGroups().get(0).addIngressRule(Peer.anyIpv4(), Port.tcp(8081)); "
},
{
	"uri": "/6-createservice/",
	"title": "Create ECS Service with CDK",
	"tags": [],
	"description": "",
	"content": "In this section, we will create an ECS Service using CDK. In this workshop, we will create the ProductService. "
},
{
	"uri": "/6-createservice/6.7-configtargergroup/",
	"title": " Configure AWS ALB Target Group and Health Check Mechanism",
	"tags": [],
	"description": "",
	"content": "Configure AWS ALB Target Group and Health Check Mechanism First, create a target group from the applicationListener using the .addTargets method with an ID of ProductsServiceAlbTarget: applicationListener.addTargets(\u0026#34;ProductsServiceAlbTarget\u0026#34;, AddApplicationTargetsProps.builder() .build() ); Set the target group name to productsServiceAlb: .targetGroupName(\u0026#34;productsServiceAlb\u0026#34;) Next, specify port 8081 for the Load Balancer to send traffic to, using the HTTP protocol to communicate with the targets: .port(8081) .protocol(ApplicationProtocol.HTTP) Next, add the list of Fargate services to the target group: .targets(Collections.singletonList(fargateService)) Next, define the deregistration delay of 30 seconds, allowing the Load Balancer to wait before deregistering an unavailable target: .deregistrationDelay(Duration.seconds(30)) Next, configure the health check and enable health check to ensure that targets are operating correctly: .healthCheck(HealthCheck.builder() .enabled(true) .build()) Kế tiếp chúng ta sẽ cấu hình khoảng thời gian giữa các lần kiểm tra sức khỏe là 30 giây và thời gian tối đa để chờ đợi phản hồi từ một target trong mỗi lần kiểm tra là 10 giây .interval(Duration.seconds(30)) .timeout(Duration.seconds(10)) Finally, declare the endpoint used to check the health of targets as /actuator/health with port 8081 used in the health check to communicate with targets: .path(\u0026#34;/actuator/health\u0026#34;) .port(8081) "
},
{
	"uri": "/7-createapigateway/",
	"title": " Create API Gateway with CDK",
	"tags": [],
	"description": "",
	"content": "In this section, we will create an API Gateway using CDK "
},
{
	"uri": "/8-createdynamodb/8.7-createcontroller/",
	"title": " Create Product Repository",
	"tags": [],
	"description": "",
	"content": "Create Product Repository Inside the products directory, create a new directory named repositories. Then, create a new file named ProductsRepository.java.\nUse @Repository to annotate the ProductsRepository class as a Spring repository bean for managing data access.\nAdd two fields to the ProductsRepository class:\nprivate final DynamoDbEnhancedAsyncClient dynamoDbEnhancedAsyncClient;: This is a final field to store an instance of DynamoDbEnhancedAsyncClient, used for asynchronous interaction with DynamoDB.\nprivate DynamoDbAsyncTable productsTable;: This is a field to store a DynamoDB table for Product objects in an asynchronous manner.\nprivate final DynamoDbEnhancedAsyncClient dynamoDbEnhancedAsyncClient; private DynamoDbAsyncTable\u0026lt;Product\u0026gt; productsTable; Create a constructor in the ProductsRepository class with the following annotations and parameters:\nAdd @Autowired, which is a Spring annotation used to automatically inject dependencies into the ProductsRepository class constructor.\nCreate a reference DynamoDbEnhancedAsyncClient dynamoDbEnhancedAsyncClient that Spring will inject into the constructor. This object will be used to interact with DynamoDB.\nCreate a reference @Value(\u0026quot;${aws.productsddb.name}\u0026quot;) String productsDdbName annotated with Spring\u0026rsquo;s @Value annotation to inject the value of a property from the application.properties configuration file. In this case, it injects the value of the property named \u0026ldquo;aws.productsddb.name\u0026rdquo; into the productsDdbName variable. This property represents the name of the DynamoDB table that ProductsRepository will interact with.\n@Autowired public ProductsRepository( DynamoDbEnhancedAsyncClient dynamoDbEnhancedAsyncClient, @Value(\u0026#34;${aws.productsddb.name}\u0026#34;) String productsDdbName) {} Initialize the dynamoDbEnhancedAsyncClient field in the ProductsRepository constructor to assign the value of dynamoDbEnhancedAsyncClient injected by Spring to the instance variable this.dynamoDbEnhancedAsyncClient. =\nthis.dynamoDbEnhancedAsyncClient = dynamoDbEnhancedAsyncClient; Initialize the productsTable field using the dynamoDbEnhancedAsyncClient to create the productsTable. The table()`method of dynamoDbEnhancedAsyncClient is called with two arguments:\nproductsDdbName: This is the name of the DynamoDB table that ProductsRepository will interact with.\nTableSchema.fromBean(Product.class): This argument creates a schema for the DynamoDB table based on the structure of the Product class. The schema defines how DynamoDB stores and reads data from Product objects.\nthis.productsTable = dynamoDbEnhancedAsyncClient.table(productsDdbName, TableSchema.fromBean(Product.class)); Next, create a method to retrieve all items from the DynamoDB table. Use productsTable.scan() to perform a scan operation on the DynamoDB table, which returns all items in the table. public PagePublisher\u0026lt;Product\u0026gt; getAll() { //DO NOT DO THIS PRODUCTION return productsTable.scan(); } Avoid using scan() in a production environment because scanning an entire DynamoDB table is not recommended in production due to potential performance and cost implications. Scanning the entire table can degrade system performance, especially for large tables.\nTạo phương thức getById nhận vào một productId và trả về một CompletableFuture, đại diện cho kết quả của việc lấy một mục Product từ bảng DynamoDB dựa trên productId. Với productsTable.getItem() là một hoạt động lấy mục (get item) từ bảng DynamoDB. Với Key.builder().partitionValue(productId).build() xây dựng một Key với giá trị partition key (productId) để truy xuất mục tương ứng từ bảng. Create a method getById that takes a productId as input and returns a CompletableFuture, representing the result of retrieving a Product item from the DynamoDB table based on the productId.\nUse productsTable.getItem() to perform a get item operation on the DynamoDB table.\nUse Key.builder().partitionValue(productId).build() to construct a Key with the partition key value (productId) to access the corresponding item from the table.\npublic CompletableFuture\u0026lt;Product\u0026gt; getById(String productId) { return productsTable.getItem(Key.builder() .partitionValue(productId) .build()); } Tạo phương thức create,phương thức này nhận vào một đối tượng Product và trả về một CompletableFuture, đại diện cho kết quả của việc tạo mới một mục Product trong bảng DynamoDB. với productsTable.putItem(product) là một hoạt động thêm mục (put item) vào bảng DynamoDB. Phương thức này sẽ đưa product vào bảng và trả về một CompletableFuture để xử lý kết quả một cách bất đồng bộ. Create a create method in the ProductsRepository class that takes a Product object as input and returns a CompletableFuture representing the result of creating a new Product item in the DynamoDB table.\nUse productsTable.putItem(product) to perform a put item operation on the DynamoDB table. This method adds the product to the table and returns a CompletableFuture to handle the result asynchronously. public CompletableFuture\u0026lt;Void\u0026gt; create(Product product) { return productsTable.putItem(product); } Create a deleteById method in the ProductsRepository class that takes a productId as input and returns a CompletableFuture representing the result of deleting a Product item from the DynamoDB table based on the productId. Use productsTable.deleteItem() to perform a delete item operation on the DynamoDB table. This method deletes the item identified by the specified productId from the table.\nUse Key.builder().partitionValue(productId).build() to construct a Key with the partition key value (productId) to identify the item to be deleted from the table.\npublic CompletableFuture\u0026lt;Product\u0026gt; deleteById(String productId) { return productsTable.deleteItem(Key.builder() .partitionValue(productId) .build()); } Create an update method in the ProductsRepository class to update a Product item in the DynamoDB table. Use product.setId(productId) to set the ID of the product to the provided productId before performing the update.\nUse productsTable.updateItem() with UpdateItemEnhancedRequest.builder(Product.class).item(product) to build an update request for the product data.\nSpecify the update condition using conditionExpression() to ensure that the id attribute of the product must exist before the update can be performed.\nThe method returns a CompletableFuture to handle the result of the update operation asynchronously.\npublic CompletableFuture\u0026lt;Product\u0026gt; update(Product product, String productId) { product.setId(productId); return productsTable.updateItem( UpdateItemEnhancedRequest.builder(Product.class) .item(product) .conditionExpression(Expression.builder() .expression(\u0026#34;attribute_exists(id)\u0026#34;) .build()) .build() ); } "
},
{
	"uri": "/6-createservice/6.8-confignlb/",
	"title": " Configure AWS Network Load Balancer",
	"tags": [],
	"description": "",
	"content": "Create a Network Listener First, initialize a NetworkListener object: NetworkListener networkListener = productsServiceProps.networkLoadBalancer() .addListener(\u0026#34;ProductsServiceNlbListener\u0026#34;, BaseNetworkListenerProps.builder() .build()); Now, configure the networkListener to listen on port 8081: .port(8081) Specify the protocol that the listener uses to listen for connections. In this case, we use TCP. .protocol(software.amazon.awscdk.services.elasticloadbalancingv2.Protocol.TCP) software.amazon.awscdk.services.elasticloadbalancingv2.Protocol.TCP: This is the way to specify the TCP protocol using CDK. Protocol.TCP is a constant in CDK representing the TCP protocol.\nConfigure NLB Target Group Use the addTargets method called on the networkListener object to add new targets to the listener previously configured on the Network Load Balancer (NLB). networkListener.addTargets(\u0026#34;ProductsServiceNlbTarget\u0026#34;, AddNetworkTargetsProps.builder() .build() ); Next, specify that connections will be sent to port 8081 on the targets. .port(8081) Connect to the targets using the TCP protocol. .protocol(software.amazon.awscdk.services.elasticloadbalancingv2.Protocol.TCP) Next, specify the name of the target group to which the targets will be added as productsServiceNlb. .targetGroupName(\u0026#34;productsServiceNlb\u0026#34;) Next, we will specify the list of specific targets that need to be added using the targets method. .targets(Collections.singletonList(/* List of targets */)) Tạo ra một target sử dụng cho dịch vụ Fargate. Một target Fargate sẽ được tạo để xử lý các kết nối gửi đến từ NLB. .targets(Collections.singletonList( fargateService.loadBalancerTarget(LoadBalancerTargetOptions.builder() .build()) )) Next, we will define the name of the container in the Fargate service to which connections will be sent as productsService. .targets(Collections.singletonList( fargateService.loadBalancerTarget(LoadBalancerTargetOptions.builder() .containerName(\u0026#34;productsService\u0026#34;) .build()) )) Finally, configure port 8081 of the container in the Fargate service to which connections will be sent, using the TCP protocol. .targets(Collections.singletonList( fargateService.loadBalancerTarget(LoadBalancerTargetOptions.builder() .containerName(\u0026#34;productsService\u0026#34;) .containerPort(8081) .protocol(Protocol.TCP) .build()) )) "
},
{
	"uri": "/8-createdynamodb/8.8-createcontroller/",
	"title": " Create Controller",
	"tags": [],
	"description": "",
	"content": "Create ProductDTO Create a directory named dto and a new file named ProductDto within it.\nDefine the ProductDTO as follows:\npublic record ProductDto( String id, String name, String code, float price, String model, @JsonInclude(JsonInclude.Include.NON_NULL) String url ) { public ProductDto(Product product) { this(product.getId(), product.getProductName(), product.getCode(), product.getPrice(), product.getModel(), product.getProductUrl()); } static public Product toProduct(ProductDto productDto) { Product product = new Product(); product.setId(product.getId()); product.setProductName(productDto.name); product.setCode(productDto.code()); product.setModel(productDto.model()); product.setPrice(productDto.price()); product.setProductUrl(productDto.url()); return product; } } Create Controller In the ProductsController class, initialize productsRepository: Declare productsRepository as a dependency injection through the constructor, used to access data from products in the database. Initialize productsRepository in the constructor using @Autowired, allowing Spring to automatically inject productsRepository into the controller. private final ProductsRepository productsRepository; @Autowired public ProductsController(ProductsRepository productsRepository) { this.productsRepository = productsRepository; } Create the getAllProducts method. This method is annotated with @GetMapping, indicating that it handles HTTP GET requests to the specified path (/products). The method includes:\nLogging the information \u0026ldquo;Get all products\u0026rdquo;. Creating an empty list productsDto to store ProductDto objects. Using productsRepository.getAll().items().subscribe(...) to retrieve a list of products from the repository. For each product retrieved from the repository, it creates a corresponding ProductDto and adds it to productsDto. Finally, the method returns a ResponseEntity\u0026lt;List\u0026lt;ProductDto\u0026gt;\u0026gt; containing the created productsDto list with an HTTP status of HttpStatus.OK. @GetMapping public ResponseEntity\u0026lt;List\u0026lt;ProductDto\u0026gt;\u0026gt; getAllProducts() { LOG.info(\u0026#34;Get all products\u0026#34;); List\u0026lt;ProductDto\u0026gt; productsDto = new ArrayList\u0026lt;\u0026gt;(); productsRepository.getAll().items().subscribe(product -\u0026gt; { productsDto.add(new ProductDto(product)); }).join(); return new ResponseEntity\u0026lt;\u0026gt;(productsDto, HttpStatus.OK); } ![Architect](/images/8/controller/04.png/?featherlight=false\u0026amp;width=60pc) 5. Create the **getProductById** method. This method is annotated with **@GetMapping(\u0026#34;{id}\u0026#34;)**, indicating that it handles HTTP GET requests to \u0026#34;/products/{id}\u0026#34;, where `{id}` is a path variable. - This method retrieves the `id` from the path and uses `productsRepository.getById(id).join()` to wait for and retrieve the `Product` from the repository. - If the `product` is not `null`, it returns the `ProductDto` of that product with an HTTP status of `HttpStatus.OK`. - If the `product` is `null`, it returns an error message \u0026#34;Product not found\u0026#34; with an HTTP status of `HttpStatus.NOT_FOUND`. ```java @GetMapping(\u0026#34;{id}\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; getProductById(@PathVariable(\u0026#34;id\u0026#34;) String id) { Product product = productsRepository.getById(id).join(); if (product != null) { return new ResponseEntity\u0026lt;\u0026gt;(new ProductDto(product), HttpStatus.OK); } else { return new ResponseEntity\u0026lt;\u0026gt;(\u0026#34;Product not found\u0026#34;, HttpStatus.NOT_FOUND); } } Create the createProduct method. This method is annotated with @PostMapping, indicating that it handles HTTP POST requests to \u0026ldquo;/products\u0026rdquo;.\nThis method creates a Product from the ProductDto sent in the request (productDto), assigns a new id using UUID.randomUUID().toString(), and then saves productCreated to productsRepository using productsRepository.create(productCreated).join(). After successfully creating the product, it logs information about the created product and returns the ProductDto of that product with an HTTP status of HttpStatus.CREATED. @PostMapping public ResponseEntity\u0026lt;ProductDto\u0026gt; createProduct(@RequestBody ProductDto productDto) { Product productCreated = ProductDto.toProduct(productDto); productCreated.setId(UUID.randomUUID().toString()); productsRepository.create(productCreated).join(); LOG.info(\u0026#34;Product created - ID: {}\u0026#34;, productCreated.getId()); return new ResponseEntity\u0026lt;\u0026gt;(new ProductDto(productCreated), HttpStatus.CREATED); } Create the deleteProductById method. This method is annotated with @DeleteMapping(\u0026quot;{id}\u0026quot;), indicating that it handles HTTP DELETE requests to \u0026ldquo;/products/{id}\u0026rdquo;.\nThis method uses productsRepository.deleteById(id).join() to delete the product from the repository. If the product is successfully deleted (productDeleted is not null), it logs information about the deleted product and returns the ProductDto of that product with an HTTP status of HttpStatus.OK. If no product is found to delete (productDeleted is null), it returns an error message \u0026ldquo;Product not found\u0026rdquo; with an HTTP status of HttpStatus.NOT_FOUND.. @DeleteMapping(\u0026#34;{id}\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; deleteProductById(@PathVariable(\u0026#34;id\u0026#34;) String id) { Product productDeleted = productsRepository.deleteById(id).join(); if (productDeleted != null) { LOG.info(\u0026#34;Product deleted - ID: {}\u0026#34;, productDeleted.getId()); return new ResponseEntity\u0026lt;\u0026gt;(new ProductDto(productDeleted), HttpStatus.OK); } else { return new ResponseEntity\u0026lt;\u0026gt;(\u0026#34;Product not found\u0026#34;, HttpStatus.NOT_FOUND); } } Create the updateProduct method. This method is annotated with @PutMapping(\u0026quot;{id}\u0026quot;), indicating that it handles HTTP PUT requests to \u0026ldquo;/products/{id}\u0026rdquo;.\nThis method updates the information of a product based on the specified id. It uses 88productsRepository.update(\u0026hellip;).join()88 to update the product in the repository. If the product is updated successfully, it logs information about the updated product and returns the ProductDto of that product with an HTTP status of 88HttpStatus.OK88. If no product is found to update (productsRepository.update(\u0026hellip;) throws a CompletionException), it returns an error message \u0026ldquo;Product not found\u0026rdquo; with an HTTP status of HttpStatus.NOT_FOUND. @PutMapping(\u0026#34;{id}\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; updateProduct(@RequestBody ProductDto productDto, @PathVariable(\u0026#34;id\u0026#34;) String id) { try { Product productUpdated = productsRepository .update(ProductDto.toProduct(productDto), id).join(); LOG.info(\u0026#34;Product updated - ID: {}\u0026#34;, productUpdated.getId()); return new ResponseEntity\u0026lt;\u0026gt;(new ProductDto(productUpdated), HttpStatus.OK); } catch (CompletionException e) { return new ResponseEntity\u0026lt;\u0026gt;(\u0026#34;Product not found\u0026#34;, HttpStatus.NOT_FOUND); } } "
},
{
	"uri": "/8-createdynamodb/",
	"title": " Create DynamoDB Table &#39;products&#39; using AWS CDK",
	"tags": [],
	"description": "",
	"content": "In this section, we will create a DynamoDB table named \u0026lsquo;products\u0026rsquo; using AWS CDK. "
},
{
	"uri": "/6-createservice/6.9-organizestack/",
	"title": " Organize and Deploy Stack",
	"tags": [],
	"description": "",
	"content": "Organize ProductsServiceStack Stack Open the root file Fcj2024CdkApp:\nCreate and Set Tags:\nCreate a Map named productsServiceTags to define tags for the stack and related resources. Tags are stored as key-value pairs in the map.\nMap\u0026lt;String, String\u0026gt; productsServiceTags = new HashMap\u0026lt;\u0026gt;(); productsServiceTags.put(\u0026#34;team\u0026#34;, \u0026#34;FirstCloudJourney\u0026#34;); productsServiceTags.put(\u0026#34;cost\u0026#34;, \u0026#34;ProductsService\u0026#34;); Create Stack ProductsServiceStack ProductsServiceStack productsServiceStack = new ProductsServiceStack(app, \u0026#34;ProductsService\u0026#34;, StackProps.builder() .env(environment) .tags(productsServiceTags) .build(), new ProductsServiceProps( vpcStack.getVpc(), clusterStack.getCluster(), nlbStack.getNetworkLoadBalancer(), nlbStack.getApplicationLoadBalancer(), ecrStack.getProductsServiceRepository())); Add Dependencies to Ensure VPC, Cluster, NLB, and ECR are Created Before Creating the Service: productsServiceStack.addDependency(vpcStack); productsServiceStack.addDependency(clusterStack); productsServiceStack.addDependency(nlbStack); productsServiceStack.addDependency(ecrStack); Deploy ProductsService Stack using AWS CDK Open a terminal and run the following command to deploy: cdk deploy --all --require-approval never After successful deployment, access the AWS Management Console. Navigate to ECS: In the ECS dashboard, you can see a cluster named ECommerce has been created along with 2 running tasks: Select the ECommerce cluster and then choose a task to view details about the created tasks: "
},
{
	"uri": "/8-createdynamodb/8.9-deploy/",
	"title": " Perform Deployment for Testing",
	"tags": [],
	"description": "",
	"content": "Perform Deployment for Testing In the productsservice project, select the Gradle icon and choose jar to package the project.\nNext, create a new image. Open the DockerFile and select Edit dockerfile.\nIn the Edit Dockerfile interface, change the image tag to 1.1.0 to create a new Docker image, then select Run.\nPush the newly created image to the ECR Repository by opening AWS Toolkit, selecting ECR, then choosing productsservice. Finally, right-click and select Push to Repository.\nIn the Push to ECR popup, select the Local image as productsservice:1.0.0 and set the Remote Tag to 1.1.0, then click Push.\nVerify the pushed image on the ECR interface.\nOpen the FCJ2024_CDK project. Then open the file ProductsServiceStack and update the tag in the fargateTaskDefinition.addContainer section to 1.1.0.\nNext, use cdk deploy --all --require-approval never to deploy the changes.\nCheck if the new task definition is running by navigating to the ECS interface, selecting the Cluster, then selecting ECommerce, and finally selecting task.\nAccess the DynamoDB interface to verify if the product table has been created.\n"
},
{
	"uri": "/9-intrumentingecs/",
	"title": "Instrumenting AWS ECS Service with AWS X-Ray",
	"tags": [],
	"description": "",
	"content": "Instrumenting AWS ECS Service with AWS X-Ray "
},
{
	"uri": "/10-cleanresource/",
	"title": "Cleanup Resources",
	"tags": [],
	"description": "",
	"content": "Cleanup Resources To delete resources, use the following command: cdk deploy --all --require-approval never "
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]